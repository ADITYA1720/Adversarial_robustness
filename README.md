# Adversarial_robustness
Adversarial robustness refers to a model's ability to resist being fooled.
